---
layout: splash
title: Call for Contributions
toc: true
---

<h1>Call for Contributions:</h1>

<font style="color: red;"><b>Update: The Deadline for Contributions has been extended to August 31, 2025.</b></font>

The IC Summit Series on [Responsible Computing, AI, and Society](https://rcais.github.io/) aims to explore the future of AI, ML, and computer vision for health, sustainability, education, and policy. The world is at an inflection point where artificial intelligence touches the lives of millions, if not billions, on a daily basis. We can no longer afford to ignore the moral and societal impacts of researching and developing computing and, especially, artificial intelligence technologies. Technology, policy, and the study of humans at the personal and societal levels can no longer remain siloed. What does it mean to develop a discipline around the responsible design, development, and deployment of computing and AI? What does it mean to design, develop, and deploy technologies responsibly? To whom are we responsible? The Summit aims to bring together luminary researchers in these areas and intersections to lay out the frontiers of these critical fields, and to plot out how they must evolve. 

The 2025 Summit will be held on Tuesday October 28th and Wednesday October 29th in Atlanta, Georgia on the Georgia Tech campus. We seek contributors to the Summit who have unique perspectives on responsibility, as well as visions for the future of responsible, ethical, moral, and/or value-aligned computing and artificial intelligence. 

- What responsibilities do we as a community hold as researchers and developers of computing and intelligent technologies? 
- What are the research questions we must address, or will we need to address in the future, to achieve positive benefits for individuals and societies and mitigate intentional or unintentional harms? 
- How should we think about responsibility, and to whom and when and why? 
- How can we pluralistically align our technologies to value systems that differ across individuals and groups? 
- How can we design AI technologies to reconcile both near-term, specific individual (and group) harms and benefits and long-term, general, societal harms and beneficence aims?  
- Value alignment seeks to design AI systems that are helpful, honest, and harmless; what considerations are missing, and/or how should these concepts be extended? 
- Future of work, leisure, and education: how should we be thinking about integrating computing technologies and AI into various aspects of human life? 
- What research challenges or problems in responsible human-AI interaction are being overlooked or under-explored? 
- What communities and groups have been ignored or marginalized by AI– why, how, and what are our pathways for authentic inclusion throughout the lifecycle of AI?

Other related topics will be considered as well. We seek contributions from a diverse set of disciplines including but not limited to computing science, engineering, policy and governance, law, social sciences, psychology, communications, health, education, sustainability, natural language processing, computer vision, fairness, accountability, transparency, explainability, agents, human-computer interaction, human-centered computing, robotics, agents, the Humanities and the Arts, design, and science and technology studies.  

To be considered for a speaking role, please submit a one-page extended abstract (approximately 750 words). We recommend the 2-column style of the [AAAI-2025 Author Kit](see https://aaai.org/authorkit25/) but do not require any particular formatting. 

Selected contributions will be presented at the Summit, Tuesday October 28th or Wednesday October 29th in person and streamed to virtual participants. Abstracts are non-archival. 

To submit an abstract, please visit the [submission management site](https://chairingtool.com/conferences/rcais2025/main-track?role=author). 

**Due date:** August 31, 2025 <font style="color: red;"><b>Updated</b></font>

**Notification:** September 15, 2025 <font style="color: red;"><b>Updated</b></font>

Tips for preparation: 

- We seek big ideas and blue-sky visions for the future of AI with respect to responsible design, development, and deployment. The work should be grounded in the current state of the contributor’s field of expertise. 
- Successful contributions will be those that look like they can have longevity; that people will return to the message in future years. 
- Contributions are recommended to build off the contributor’s body of work—it is acceptable and welcome to describe current, recent, and upcoming research—but should not just be a research report on completed work. 
- Extended abstracts do not need to be well-polished. They are meant to guide the selection committee about what the summit should expect to hear in a presentation. The strength of the core ideas, arguments, and vision is paramount. The extended abstracts are non-archival. Authors are welcome, and encouraged, to refine their abstracts and post to arXiv, blog posts, etc., but the submitted version need not be public-ready. 
